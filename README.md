# Updating, Maintenance & Scaling
So far, our team have done the basic setup of our object detection pipeline for security systems. If you followed all the steps covered in previous six writeups, you should have got a similar pipeline that can automatically run on a remote server to validate images, detect objects as well as threats, send alerts and generate a plot. However, we haven't reach the end of the project. This writeup discusses what you can do in the long run to update, debug, maintain or scale your pipeline, followed by some ideas of improvement you may apply to your pipeline.

Remainders what we do last week about piepiline and insfrasutrec.
each of those squreas is some cod ewe written and deckerlized and deploy the pipeline in this way and we have pipeline specification. Tell peruyderm and k8s how to deploy one of thises stages on one of the underling computer nodes. And echa of those places where those data is a verison collection fo data that’s came mange the inputs and outputs and  backed up in object store. 
## Updating the Pipeline
First thing you might want to do is updateing. Typitally, you might want to add another processing stage to the pipieline , such as another visualtion stage. Or yu may want to change and improve the code of existing stage running on k8s nodes. To acheive this, the first thing is to develop a beter algrithism locally. You should never directly modify your working code, instnead try to modify your code and fully test it locally before deploying it elsewhere. When you are satisfied with your local code, you can move to the cloud. At this point, the running conatiern is the old conaicnter which contianes the old codes

we already put there. Now the questions is how we do that. First step, we wna to change we have a validate stage and a onject dection stage, we want to improve  our moder in object detection stage to improve the .. say the cluster is pu and running 35?,we want ot try and improve our ifrence stage or change in some way, best  way is not to twiking things lareday working doeypiloyed. Before twtiwng anything, want , 

I like want I see and I want to replace what’s up here what I have locally, the contierne running here is the old container, contains the old codes, so soemhwo we wnt to stop that running, and to deploy  a new reopistory of new container with the new code, but all I have doen is update my python code. I change my code, build the new container and then satart running the new conaitner, last time we named our coantiners, this is magmente validate, I rebuilt thatcontiner and I called it management valditae coantier  and then I tell this cluster hi you should run management vilaid for this stage, what ‘s the problem, there is no unique nmane, you alrady told me that, tis’ already running, caretae a new tage for iamge  wighch correspond to the new version fo our code. Ones we have the new tag image, if we told that cluster hi you nedd to runthat new tage image, then they now the diference, its; gonnga stop the other one and star the new one.
Hteres my threat detect code, test make a triaval chage, so now wht I need to do ,istill have the docker file about how to build the image, so I just need to rebuild the image, so that the new code goes in there rather than the old code. In chaign g your code, you might add dependency or soenthing, so you might hav eto change the docker file, in other cases, likely you just change the code, and just run with the same docker file. Call it mangaem ment thrata detect , goie it a specif tag, version 2, here this is a dfeirvnets ways to tag your images, if it workd fine for you, that is fine, likely you odn’ eawnt to do tag mnage thetar edectect code my fith version form last wensesday. No one else gonna know what you ifth verison form last wesdsay is. You either gong use semitic versioning numners like this, coreponiding to github, there is version 2 on github, this is the version to image or your can autimaltly gerentate your tag with you github commanded, when you make a commit to gethub, it altumiatlclay build the docket image and tag that with the commit id, socu that , you can always tag exactly that version to your code, here just tag version2 should be surfiicent for this demonstration. I buildmy new docker image, nuo I gonna push up that new docker image to dokcer hub, sp you can a lot of things alre day ezisted. The layers, one payre got pushed, the other pyers get added, the new code, I now push this new imga. Then I can go here , the therect detect .json and I can say I have new code, I no linge want otyou to run this with my old code, which is thereate detect, I WANT TO RUNIWTH NEW CODE  VERSION TO, AND KNOW. Here is all this things running on my cluster, I want you to undeate this pipileine with this new vrsion. Terminate, psinup the new container, now if I put in another iamge, again it will triger all that work, its running pot, at this job, logs , it I look at the previous one, , so atctually thtere wnrst object detect, thresahold to the python sript, we can change the threashold, update the pipieline same way. When we told k and p it should be running the new thing, the old things is delted na drun the new thing. The ocmna dwe run is just update pipilen, we give, the .json, we just change the name of image, I’m telling you cluistser, youshould run the image. 
It already hav eth other layers, it just have to in the differnece , which is very small. Replamet in java, the lag would be greater. If you have a java running, allthat’s fine, it wil get the data running through when it get the new imgae up and running, could b ea lag in procees. Some sort of savin thing. In a silierd verion, we have images coming in , andwe have object detect, we have athe ouptu, this wiwhat up and running, what we might do is just create a totally speratepipieline bu subscribed to the same data, so here is my new object detect ,and that’ s gonna run when ever the other runs and produce data andthen this might go to the rest of our pipieline, what we will do is taking this guys as compriasion to see how new guys operaiting, even tualy this works fine, we can just update to this new imge, and delet the old one. 

## Debugging and Maintenance
Although you can ensure the pipieline is well-desinged and fully-tested, things can still go wrong. In that case, you need some approaches to debug, so that you know which part of the code goes wrong. Also, as you update your pipieline from time to time, you may for some reason want to know the version of code related to a specific result, which .
 so all of that you can get form a combination of your logs to your code and the proviance traking in paetyderm. If you running a poyhton program, get you ar putting an ouput , you can see that when you loaclaly, if you run it osmehtinger else, when you in dokcer, you can still accsee thaose ologhse, you just have to aces stieothuc some tolls, you can acess it via docker directly bu there is confiventce aroufd that, there is all of this pipieline pots running, ican grabe the nmaen one of this pods nad o cude control logs po menasi pod, its going to I have abunkvs of jobs, for each of this is a java id, garbe that java id and get the log for that java with the command, you souhl eb following th same way you would be loging in in a normal python program, you cen log and lokk at this thing to see is there any ereor. If we run things multiple times, in outr pipilien, we are versioning eiach of this colecitons of data, everytihg change we made to on eoftheocllecitons of data is versioned, and also I know what has proceosed wht data t what time, that’s the imagemation fo the java, spot he sombinations of the two of this things gives us idea whtere is probpke. If im traking hat imfroamtion, I can lok at for exxapmle an output like this plot, and icna say what were all the other pieces awhat was the stage of the other piece of data when that plot wa generated so your data and code is chaning all the time, you want to know anypoint at time, what wre all the piece of data nd code that produce this specific results at the specifc time.  This is another jobrun pricoiesly in history, I wna tot knowwhteres all piece sof dat being generated. Java id, ad then there is this bit of imafoee, which is the commit id of the output, with git, when you make a commit, there si id with change. So in the same way, the version collection of data, whanever, thet is an othout pot input o rhcnage to naypievce of data, ifd asocoiated, theis is the id ascoaiiiied with job for tha tproericlaur plot, ispect that comit of plot and what well see this is ishtis nice reperosetation,this is the stage of validaita of my vaidlation dta when plot wad generated, this is the dtat from object dection output,..eta. and put ervertyihign back together, so you can actually reproceruse any particular resuls. Fro any stage anty piece of data theries I coid id, lets get therules file at this partiam time, get a this me this pratiglar file in genterating the plot, go backto the prievous verison. It will give me back whaereve. Here is th pipilien, here is th eimformation about input was, you ere usin gwhta stage. Allthe stausts of data and docker image. I can know hat happned and dlei with them. Get file rules master, list file theret detect, I can seethere is one directory. 
## Distributed Computing
We have nodes up and one nodes have all of our pipieline stages runin in our cluster, that’s fine, but if if we strat toprocess a thousand imges a mniute, then probably we goona .. very uwikclt, ideally, is bootle neck on objcetdetect, takes a lot of time, akte that stage and disturbueted, so spin up mu;tiple instanceso fthat iamgesand spersa that across over those instacnes. As oppose to hodoero, I actually don’ thave to change my code to do this, all I need to do is spin up a buhc of incteansce of that code, and then have something shares the data acrosso those instaces runin gmy code, and we oding things this way pretty easy, I nolongerwnat to runone of this, Inwant to run 5 , in the same way we updeta other things, we can update piepieline, and now what willhappend, iamedeitley I have fieive therets detect, autoaelteam when images coming in, p will autamicallty spelit those files acrosso whtose five workers to be procesedin pareller. Constant, set to becoefcient of your cluster size, 4th of my cluster size, 8 nodes. But if you have autosaclei, if the cluster, a nd sipn up more of those workers. Now let s pub some more data here, put all this images in one time, -r do everyhitng here recerveilly, putin ghtme al at one, doing thisn swe did before. Any stage. 
## Improvements, Next Steps
Video feed, depedndieng on whtwformat it is, likely frames of images, not necesry anlayise all everysingle video feed to all deivcesc, most will be blank won’t be anything in the video.waste effort. Some ceamores are motion triger, instead of video in front of me this is like a 30 secon video or somehign work in fornt of our camero, it might bethat, or mghit if some thing triggered by motion, then it starts sending htose frmaes in real time to do detection.
We may also want to modify our notification system, we have 5000frames of video, we won’t wna tot send someone 5000 emails, we maight want to find someway of grouping things into a corespining eventor something ,possible, improving things. Same mahilering will work, jus twik things around.
Add an initial prasion stages, covoerta format of video to a collection of iamges, and then gourp them under a directory. Insntead of processing per imgae, we may processing per batch. Per sest of images correspoing to a particular event.

